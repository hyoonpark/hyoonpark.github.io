---
layout: post
title: "[Computer Architecture] 캐시 메모리"
date: 2025-04-16 10:48 +09:00
categories: cs computerarchitecture
tags:
    [
        github,
        tech,
        blog,
        memory,
        cache,
        computer,
        architecture
    ]
---

> **3줄 요약**
<br>캐시 메모리는 **CPU와 메모리 사이에 위치한** 빠르고 작은 저장 장치로,
<br>**CPU의 연산 속도와 메모리 접근 속도 차이**를 줄이기 위해 사용
<br>**L1, L2, L3 캐시**는 **계층적 구조**로 성능을 최적화하고, **참조 지역성** 원리에 기반하여 데이터를 예측
{: .prompt-tip }

# 💻 컴퓨터 구조 & 운영체제 시리즈

> 이 시리즈는 『혼자 공부하는 컴퓨터 구조+운영체제』 (강민철 저)
> <br> + 인프런 강의를 기반으로 **개인적으로 복습 및 정리한 기록**입니다.

---

## 💾 캐시 메모리

- **CPU와 메모리 사이에 위치한** SRAM 기반의 저장 장치로, **레지스터보다 용량이 크고, 메모리보다 빠름**
- **CPU의 연산 속도**와 **메모리 접근 속도** 차이를 줄이기 위한 저장 장치로, **빠른 데이터 접근**이 가능

### 🔸 저장 장치 계층 구조

1. **CPU와 가까운 저장 장치**는 빠르고, **멀리 있는 저장 장치**는 느림  
2. 속도가 빠른 저장 장치는 **저장 용량이 작고, 가격이 비쌈**  
   - 예: **레지스터 < 캐시 메모리 < RAM < 보조기억장치**

### 🔸 계층적 캐시 메모리 (L1, L2, L3 캐시)

- **L1, L2** 캐시는 **CPU 코어 내부에 위치**하고, **L3**는 **CPU 외부**에 위치하여 여러 코어와 공유  
- **L1 캐시**: 가장 빠르지만 용량이 작고, **CPU 내부**에서 바로 접근 가능  
- **L2 캐시**: 속도는 L1보다 느리지만, **용량이 더 크고** 여전히 빠름  
- **L3 캐시**: 여러 CPU 코어와 **공유되며, 용량이 크지만 상대적으로 느림**

### 🔸 참조 지역성의 원리 (Locality of Reference)

- CPU가 자주 사용할 법한 데이터를 **예측하여 저장**하고, 이를 통해 속도 향상  
  - 예측이 맞을 경우: **캐시 히트**  
  - 예측이 틀렸을 경우: **캐시 미스**  
  - **캐시 적중률** = `캐시 히트 / (캐시 히트 + 캐시 미스)`
  
- **CPU가 메모리에 접근할 때의 경향**  
  1. **시간 지역성**: 최근에 접근한 데이터는 다시 접근할 확률이 높음  
  2. **공간 지역성**: 데이터를 읽은 후, 그 인접 영역을 읽을 확률이 높음

---

## ✅ 마무리 정리

**캐시 메모리**는 **CPU**와 **메모리** 사이에서 데이터 접근 속도를 최적화하는 핵심적인 역할  
**L1, L2, L3 캐시**는 각기 다른 속도와 용량을 가진 **계층적 구조**로 성능을 높이며,  
**참조 지역성** 원리를 통해 CPU의 메모리 접근 패턴을 예측하여 **속도를 최적화**

---

## 📚 참고 자료

- 『혼자 공부하는 컴퓨터 구조+운영체제』 - 강민철 저  
- [인프런 강의 - 혼자 공부하는 컴퓨터 구조+운영체제 기반 강의](https://www.inflearn.com/course/%ED%98%BC%EC%9E%90-%EA%B3%B5%EB%B6%80%ED%95%98%EB%8A%94-%EC%BB%B4%ED%93%A8%ED%84%B0%EA%B5%AC%EC%A1%B0-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C)  
{: target="_blank"}

---

읽어주셔서 감사합니다 🙌  
내용이 도움이 되었거나, 틀린 부분이 있다면 댓글이나 GitHub Issue로 알려주세요 😊
